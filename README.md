Tema 4. ILUMINACI√ìN parte 1 de 3 , abajo parte 2
4.1. Importancia de la iluminaci√≥n en visi√≥n por computadora.

4.2. Problemas relacionados con la iluminaci√≥n.

4.3. Preprocesamiento de im√°genes.

4.4. Aumento de datos espec√≠fico para la iluminaci√≥n.

READMEN DE REPORTE
# üêï Proyecci√≥n de Im√°genes con PCA y UMAP (Stanford Dogs Dataset)

## üìå Tarea de la Semana 9: An√°lisis Visual de Dimensionalidad

Este proyecto aplica t√©cnicas de **reducci√≥n de dimensionalidad** (PCA y UMAP) sobre un subconjunto del **Stanford Dogs Dataset** para visualizar c√≥mo se agrupan las diferentes razas en un espacio de baja dimensi√≥n (2D y 3D), despu√©s de un preprocesamiento de im√°genes que incluye aumento de iluminaci√≥n.

### üéØ Objetivo

Visualizar la estructura latente de las representaciones de im√°genes mediante t√©cnicas lineales y no lineales, demostrando la robustez de las caracter√≠sticas de la imagen frente a variaciones de iluminaci√≥n.

### üõ†Ô∏è Pipeline de Procesamiento

1.  **Carga del Dataset:** Extracci√≥n del conjunto de im√°genes del Stanford Dogs Dataset.
2.  **Aumento de Iluminaci√≥n:** Aplicaci√≥n de variaciones aleatorias de **Brillo ($\beta$)** y **Contraste ($\alpha$)** a cada imagen para simular diversas condiciones de luz y mejorar la robustez.
    $$\text{Imagen Ajustada} = \alpha \cdot \text{Imagen Original} + \beta$$
3.  **Conversi√≥n y Aplanamiento:**
    * Redimensi√≥n a $128 \times 128 \times 3$ y normalizaci√≥n a $[0, 1]$.
    * Aplanamiento del tensor 4D a una matriz de vectores de caracter√≠sticas de alta dimensi√≥n.
4.  **Reducci√≥n de Dimensionalidad:** Proyecci√≥n de los vectores a 3 dimensiones utilizando:
    * **PCA (An√°lisis de Componentes Principales):** M√©todo lineal que maximiza la varianza.
    * **UMAP (Uniform Manifold Approximation and Projection):** M√©todo no lineal que preserva la estructura topol√≥gica local.

### üìä Resultados y An√°lisis

Los resultados se visualizan mediante gr√°ficos de dispersi√≥n 2D y 3D, donde cada punto representa una imagen y el color indica la raza.

* **PCA:** Muestra una **superposici√≥n significativa** de las razas, lo que sugiere que las caracter√≠sticas distintivas de las razas no son linealmente separables en los primeros componentes principales.
* **UMAP:** Logra una **mejor segregaci√≥n y cl√∫steres m√°s compactos**, demostrando su capacidad para capturar las relaciones no lineales y la estructura intr√≠nseca del *manifold* de las im√°genes.

### üì¶ Tecnolog√≠as Utilizadas

* `Python 3.x`
* `scikit-learn` (para PCA)
* `umap-learn` (para UMAP)
* `OpenCV (cv2)` (para Preprocesamiento de im√°genes)
* `matplotlib`, `seaborn`, `plotly` (para Visualizaci√≥n)
* `numpy`

### üöÄ Uso

1.  Clonar el repositorio.
2.  Asegurar el archivo `perros.zip` del Stanford Dogs Dataset en la ruta de trabajo.
3.  Ejecutar el *notebook* de Colab o Jupyter.


PARTE 2 DE 3
# üí° DEEP LEARNIN & ML_ILUMINACION_VISION_COMPUTADORA

## üìÑ Semana 10: Fundamentos de CNN, Convoluci√≥n y Pooling

Este repositorio contiene el c√≥digo desarrollado y ejecutado para la demostraci√≥n de los componentes fundamentales de las Redes Neuronales Convolucionales (CNN) y su aplicaci√≥n inicial en el contexto de la visi√≥n por computadora.

El enfoque principal de este notebook es la **validaci√≥n conceptual** de c√≥mo los modelos procesan datos espaciales (im√°genes), desde la unidad m√°s b√°sica (el perceptr√≥n) hasta las operaciones clave de una capa convolucional.

### üõ†Ô∏è Contenido del Notebook

El archivo `Semana_10_Con tarea.ipynb` incluye las siguientes demostraciones pr√°cticas:

1.  **Perceptr√≥n y Separabilidad Lineal:** Implementaci√≥n y entrenamiento de un perceptr√≥n simple para resolver la compuerta l√≥gica AND, incluyendo la visualizaci√≥n de la frontera de decisi√≥n.
2.  **Convoluci√≥n 2D Fundamental:** Demostraci√≥n manual de la operaci√≥n de convoluci√≥n utilizando una imagen artificial y un kernel detector de bordes, ilustrando el proceso de generaci√≥n de mapas de caracter√≠sticas.
3.  **Pipeline de Procesamiento CNN en Im√°genes Reales:** Aplicaci√≥n de filtros de convoluci√≥n y la operaci√≥n de Max Pooling sobre im√°genes del Stanford Dogs Dataset (o im√°genes de ejemplo) para simular la extracci√≥n de caracter√≠sticas y la reducci√≥n de dimensionalidad espacial:
    * Detecci√≥n de Bordes (Filtro Sobel/Laplaciano).
    * Suavizado (*Blur*).
    * Max Pooling Iterativo (generaci√≥n de una jerarqu√≠a de caracter√≠sticas abstractas).

### üéØ Objetivos de Aprendizaje

* Comprender el rol de la neurona y las funciones de activaci√≥n (ReLU, Sigmoide).
* Visualizar la **invariancia traslacional** lograda mediante el compartimiento de pesos en la convoluci√≥n.
* Analizar c√≥mo la operaci√≥n de **Max Pooling** reduce la resoluci√≥n mientras conserva las caracter√≠sticas dominantes, contribuyendo a la robustez del modelo.

### üì¶ Dependencias

* numpy
* matplotlib
* opencv-python (cv2)


PARTE 3 DE 3

# üê∂ Clasificaci√≥n Avanzada de Im√°genes con Deep Learning (Stanford Dogs Dataset)



[Image of a deep learning model architecture for image classification]


Este repositorio aborda la desafiante tarea de la **Clasificaci√≥n de Grano Fino (Fine-Grained Classification)** utilizando el **Stanford Dogs Dataset** (120 razas de perros). El objetivo principal es la implementaci√≥n, el entrenamiento y el **an√°lisis comparativo** de distintas arquitecturas de Deep Learning (DL) y la t√©cnica de Transferencia de Conocimiento.

---

## üí° Objetivos y Enfoque

El proyecto busca evaluar y contrastar el **rendimiento** y la **eficiencia** de diversos modelos neuronales en un contexto de alta complejidad visual, donde las diferencias entre las clases (razas) son sutiles.

### Arquitecturas a Evaluar

1.  **MLP (L√≠nea Base):** Para establecer el rendimiento sin estructura espacial.
2.  **LSTM Bidireccional:** Eval√∫a la imagen como una secuencia de datos.
3.  **CNN Baseline:** El est√°ndar para Computer Vision, extrayendo jerarqu√≠as de caracter√≠sticas locales.
4.  **Transfer Learning (MobileNetV2):** Reutilizaci√≥n de conocimiento preentrenado en ImageNet para m√°xima precisi√≥n y r√°pida convergencia.

---

## üõ†Ô∏è Estructura del Pipeline de Entrenamiento

El c√≥digo sigue un protocolo de experimentaci√≥n riguroso, optimizado para la **reproducibilidad** y el rendimiento, utilizando TensorFlow y Keras.

### 1. Preparaci√≥n y Optimizaci√≥n del Dataset

* **Reproducibilidad:** Se utiliza una semilla fija (`SEED = 42`) para garantizar la consistencia en la divisi√≥n de datos y la inicializaci√≥n de pesos.
* **Pipeline de Datos (`tf.data`):** Implementaci√≥n de t√©cnicas avanzadas como **caching**, **prefetching** y **shuffling** para maximizar el rendimiento de la GPU/CPU durante el entrenamiento.
* **Normalizaci√≥n:** Escalado de las im√°genes al rango $[0, 1]$.
* **Adaptaci√≥n de Tensors:** Funciones espec√≠ficas para reestructurar la entrada seg√∫n la arquitectura:
    * **MLP:** Imagen aplanada a vector 1D.
    * **LSTM:** Imagen transformada a una secuencia de filas (`Tiempo x Caracter√≠sticas`).
    * **CNN/TL:** Mantenimiento de la forma espacial (`H x W x C`).

### 2. Control del Aprendizaje (Callbacks)

Se emplean Callbacks para gestionar el proceso de entrenamiento de forma autom√°tica y robusta:

* `EarlyStopping`: Detiene el entrenamiento al detectar **sobreajuste** (monitoreando la p√©rdida de validaci√≥n).
* `ReduceLROnPlateau`: Ajusta din√°micamente la **tasa de aprendizaje** para mejorar la convergencia en etapas finales.
* `ModelCheckpoint`: Guarda la versi√≥n del modelo que alcanza el **mejor desempe√±o** en el conjunto de validaci√≥n.

### 3. Comparativa de Arquitecturas

El coraz√≥n del proyecto es la comparaci√≥n de los cuatro enfoques:

| Modelo | Tipo de Estructura | Funci√≥n en el An√°lisis |
| :--- | :--- | :--- |
| **MLP (L√≠nea Base)** | Vectorial (Densas) | Eval√∫a el desempe√±o sin estructura espacial. |
| **LSTM Bidireccional** | Secuencial/Temporal | Eval√∫a la imagen como una secuencia de filas. |
| **CNN Baseline** | Espacial (Convolucional) | Est√°ndar para CV; extrae jerarqu√≠as de caracter√≠sticas locales. |
| **Transfer Learning** | Preentrenado + Fine-Tuning | M√°xima precisi√≥n y r√°pida convergencia. |

---

## üìä Evaluaci√≥n Profunda

El c√≥digo incluye un conjunto de funciones de evaluaci√≥n avanzadas para una visi√≥n integral del rendimiento del modelo:

* `plot_history`: Visualizaci√≥n de curvas de **P√©rdida (Loss)** y **Precisi√≥n (Accuracy)** en entrenamiento y validaci√≥n.
* `eval_and_report`: Generaci√≥n del **Reporte de Clasificaci√≥n** (Precisi√≥n, Recall, F1-Score por clase) y la **Matriz de Confusi√≥n** (`heatmap`).
* `show_sample_predictions`: Muestras visuales de las predicciones (**aciertos ‚úÖ / errores ‚ùå**) para un an√°lisis cualitativo.



[Image of a confusion matrix heatmap]


---

## üöÄ Tecnolog√≠as Clave

* **Python 3.x**
* **TensorFlow / Keras** (Core DL framework)
* **tf.data** (Optimizaci√≥n de pipelines de datos)
* **numpy**
* **matplotlib** y **seaborn** (Visualizaci√≥n de resultados)
* **scikit-learn** (Generaci√≥n de Reportes y Matriz de Confusi√≥n)
